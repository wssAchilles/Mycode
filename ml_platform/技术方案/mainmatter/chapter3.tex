\chapter{功能模块设计}
平台功能围绕核心的可视化引擎进行构建，采用模块化设计确保系统的可扩展性和可维护性。

\section{核心可视化引擎 (Core Visualization Engine)}
这是整个平台的技术核心，是一个抽象的、可复用的模块，为所有可视化内容提供统一的底层支持。引擎采用状态机（State Machine）模式设计，负责：

\begin{itemize}
    \item \textbf{状态管理:} 管理算法或系统在每一步的状态数据（如数组元素、指针位置、变量值等），支持状态的保存、恢复和历史记录功能。状态采用不可变数据结构（Immutable Data Structure）设计，确保状态转换的可追溯性和调试友好性。
    
    \item \textbf{渲染逻辑:} 将抽象的状态数据渲染成直观的图形界面（如节点、边、指针、内存块、进程队列等）。渲染层与业务逻辑分离，采用声明式UI（Declarative UI）模式，状态变化自动触发界面更新。
    
    \item \textbf{动画控制:} 提供完整的动画控制接口，包括播放、暂停、单步前进/后退、跳转到指定步骤、调整动画速度、重置等功能。支持自动播放模式和手动探索模式的无缝切换。
    
    \item \textbf{交互接口:} 允许用户通过多种方式与可视化内容交互：输入自定义数据（如数组、图的邻接矩阵、进程参数）、拖拽元素改变初始状态、点击触发特定操作。所有交互行为实时反馈到状态机，并更新可视化展示。
    
    \item \textbf{配置化与可扩展性:} 支持通过JSON格式的配置文件定义可视化元素的样式（颜色、大小、字体）、动画参数（速度、缓动函数）和布局规则。这种设计使得添加新的算法或原理可视化时，只需编写相应的状态转换逻辑和配置文件，无需修改引擎核心代码，大幅降低了扩展成本。
    
    \item \textbf{性能优化:} 采用增量渲染（Incremental Rendering）技术，只重绘发生变化的部分，避免全量刷新；对复杂场景（如大规模图数据）使用虚拟滚动（Virtual Scrolling）和LOD（Level of Detail）技术，确保60 FPS的流畅度。
\end{itemize}

\section{数据结构模块}

数据结构模块是平台内容的核心组成部分，旨在通过动态可视化帮助学习者理解各种数据结构的本质特征和操作原理。该模块的设计充分体现了"408"考试大纲对数据结构知识的要求，覆盖了从基础线性结构到复杂图结构的完整知识体系。

\subsection{可视化工作区设计}

可视化工作区采用经典的三栏式布局设计，这种设计源于对人类视觉注意力分配规律的深入理解。左侧区域承载理论讲解和伪代码展示功能，当算法执行时，当前步骤对应的伪代码行将以高亮方式呈现，这种同步展示机制能够帮助学习者建立代码逻辑与执行过程之间的直接映射关系。中间区域是可视化动画的主画布，这是用户视觉焦点的主要区域，所有数据结构的状态变化、元素移动、指针调整等操作都在此区域以动画形式呈现。动画的帧率维持在60 FPS以确保流畅性，同时支持速度调节，适应不同学习者的节奏需求。右侧区域整合了控制面板和数据输出功能，控制面板允许用户输入自定义数据、选择算法参数、控制动画播放（播放、暂停、单步前进、单步后退、重置），数据输出区实时显示当前状态下的关键变量值、比较次数、交换次数等统计信息，这些量化指标有助于学习者从数学角度理解算法的性能特征。

\subsection{核心算法与复杂度分析}

数据结构模块涵盖了"408"考纲要求的全部核心内容。在线性表方面，平台展示了数组和链表的基本操作，包括插入、删除、查找和遍历。数组的随机访问时间复杂度为$O(1)$，但插入和删除操作在最坏情况下需要$O(n)$的时间，因为可能需要移动大量元素。链表则在插入和删除方面具有优势，时间复杂度为$O(1)$（假设已知插入位置），但查找操作需要$O(n)$的时间进行线性扫描。

栈与队列作为特殊的线性结构，遵循特定的访问规则。栈遵循后进先出（LIFO）原则，其push和pop操作的时间复杂度均为$O(1)$。队列遵循先进先出（FIFO）原则，enqueue和dequeue操作同样为$O(1)$。平台通过动画清晰展示了这些抽象数据类型（ADT）的操作语义。

树形结构是数据结构教学的重点和难点。二叉搜索树（BST）的查找、插入和删除操作在平衡情况下的时间复杂度为$O(\log n)$，但在最坏情况下（退化为链表）会降至$O(n)$。平台展示了BST的构建过程，以及如何通过中序遍历得到有序序列。AVL树作为自平衡二叉搜索树，通过旋转操作（左旋、右旋、左右旋、右左旋）维持平衡因子$|h_L - h_R| \leq 1$的约束，保证所有操作的时间复杂度为$O(\log n)$。平台动态演示了插入节点后如何检测不平衡并通过适当的旋转恢复平衡，这一过程对于理解自平衡树的核心思想至关重要。堆作为完全二叉树的特殊形式，满足堆序性质（最大堆：$key(parent) \geq key(child)$），其构建过程的时间复杂度为$O(n)$，堆排序的整体时间复杂度为$O(n\log n)$。

图结构是最复杂的非线性数据结构。平台实现了深度优先搜索（DFS）和广度优先搜索（BFS）的可视化，这两种遍历策略分别采用栈（递归调用栈）和队列实现，时间复杂度均为$O(V+E)$，其中$V$为顶点数，$E$为边数。在最小生成树问题上，Prim算法和Kruskal算法都能找到权重和最小的生成树，前者基于贪心策略从单个顶点开始逐步扩展，时间复杂度为$O(E\log V)$（使用优先队列）；后者按边权重排序后逐条加入，使用并查集判断是否形成环，时间复杂度为$O(E\log E)$。最短路径问题的Dijkstra算法通过维护距离数组$dist[]$和已访问集合$S$，每次选择$dist$值最小的未访问顶点进行松弛操作，时间复杂度为$O(V^2)$（朴素实现）或$O(E\log V)$（使用堆优化）。Floyd算法采用动态规划思想，通过三重循环计算任意两点间的最短路径，时间复杂度为$O(V^3)$，其核心递推关系为：
\begin{equation}
dist[i][j] = \min(dist[i][j], dist[i][k] + dist[k][j])
\end{equation}
平台通过动画展示了Dijkstra算法的贪心扩展过程和Floyd算法的动态规划矩阵更新过程\cite{Korhonen2002Environment}。

排序算法是数据结构课程的经典内容。平台实现了冒泡排序、选择排序、插入排序、快速排序、归并排序和堆排序的完整可视化。表\ref{tab:sort_complexity}总结了各排序算法的性能特征。

\begin{table}[htbp]
    \centering
    \caption{排序算法复杂度对比}
    \label{tab:sort_complexity}
    \begin{tabular}{|l|c|c|c|c|c|}
        \hline
        \textbf{算法} & \textbf{最好} & \textbf{平均} & \textbf{最坏} & \textbf{空间} & \textbf{稳定性} \\
        \hline
        冒泡排序 & $O(n)$ & $O(n^2)$ & $O(n^2)$ & $O(1)$ & 稳定 \\
        \hline
        选择排序 & $O(n^2)$ & $O(n^2)$ & $O(n^2)$ & $O(1)$ & 不稳定 \\
        \hline
        插入排序 & $O(n)$ & $O(n^2)$ & $O(n^2)$ & $O(1)$ & 稳定 \\
        \hline
        快速排序 & $O(n\log n)$ & $O(n\log n)$ & $O(n^2)$ & $O(\log n)$ & 不稳定 \\
        \hline
        归并排序 & $O(n\log n)$ & $O(n\log n)$ & $O(n\log n)$ & $O(n)$ & 稳定 \\
        \hline
        堆排序 & $O(n\log n)$ & $O(n\log n)$ & $O(n\log n)$ & $O(1)$ & 不稳定 \\
        \hline
    \end{tabular}
\end{table}

快速排序作为实践中最常用的排序算法，其核心思想是分治法。算法选择一个枢轴元素（pivot），通过分区操作将数组划分为两个子数组，使得左侧元素都小于等于pivot，右侧元素都大于等于pivot，然后递归地对两个子数组进行排序。其平均时间复杂度的数学期望为：
\begin{equation}
T(n) = T(k) + T(n-k-1) + O(n)
\end{equation}
其中$k$是pivot的位置，平均情况下$k \approx n/2$，解得$T(n) = O(n\log n)$。

\section{操作系统模块}

操作系统模块致力于将抽象的系统概念具象化，通过动态模拟帮助学习者理解操作系统的核心机制。该模块涵盖进程管理、内存管理和死锁处理三大核心主题，这些都是"408"操作系统考试的重点内容。

\subsection{进程调度算法可视化}

进程调度是操作系统资源管理的核心问题之一。调度算法的目标是在满足系统响应时间、吞吐量、公平性等多个性能指标的前提下，合理分配CPU时间。平台允许用户自定义进程列表，为每个进程指定到达时间（Arrival Time）、服务时间（Burst Time）和优先级（Priority），然后直观地观察不同调度算法的执行过程。

先来先服务（FCFS, First-Come-First-Served）是最简单的调度算法，按进程到达顺序依次执行。设有$n$个进程，第$i$个进程的等待时间为$W_i = \sum_{j=1}^{i-1} B_j$，平均等待时间为：
\begin{equation}
\overline{W} = \frac{1}{n}\sum_{i=1}^{n} W_i
\end{equation}
FCFS的缺点是可能导致"护航效应"（Convoy Effect），即短作业被长作业阻塞。

最短作业优先（SJF, Shortest Job First）选择服务时间最短的进程优先执行，这在理论上能够最小化平均等待时间。可以证明，SJF是最优的非抢占式调度算法。然而，SJF的实现面临一个根本性困难：无法准确预测进程的服务时间。实践中通常使用指数平滑法预测：
\begin{equation}
\tau_{n+1} = \alpha t_n + (1-\alpha)\tau_n
\end{equation}
其中$t_n$是第$n$次实际执行时间，$\tau_n$是预测值，$\alpha \in [0,1]$是平滑系数。

优先级调度算法为每个进程分配一个优先级，总是选择优先级最高的就绪进程执行。这种算法可能导致低优先级进程"饥饿"（Starvation）问题，解决方法是引入优先级老化（Aging）机制，随着等待时间增加逐步提升进程优先级。

时间片轮转（RR, Round Robin）算法是抢占式调度的经典实现，特别适合分时系统。系统维护一个就绪队列，为每个进程分配一个时间片（Time Quantum）$q$，进程执行$q$时间后被抢占并移至队列尾部。时间片的选择至关重要：$q$过大则退化为FCFS，$q$过小则上下文切换开销过大。设上下文切换时间为$t_c$，则CPU利用率可近似为：
\begin{equation}
CPU\_Utilization \approx \frac{q}{q + t_c}
\end{equation}

平台通过动态的甘特图（Gantt Chart）展示进程在就绪、运行、阻塞三种状态间的转换，并实时计算平均等待时间、平均周转时间等性能指标，帮助学习者直观理解不同调度算法的优劣。

\begin{table}[htbp]
    \centering
    \caption{进程调度算法性能对比}
    \label{tab:scheduling_comparison}
    \begin{tabular}{|l|c|c|c|c|}
        \hline
        \textbf{算法} & \textbf{抢占性} & \textbf{平均等待时间} & \textbf{响应时间} & \textbf{饥饿风险} \\
        \hline
        FCFS & 非抢占 & 较高 & 较差 & 无 \\
        \hline
        SJF & 非抢占 & 最优 & 较差（长作业） & 有（长作业） \\
        \hline
        优先级 & 可选 & 取决于优先级 & 好（高优先级） & 有（低优先级） \\
        \hline
        时间片轮转 & 抢占 & 中等 & 好 & 无 \\
        \hline
    \end{tabular}
\end{table}

\subsection{内存管理机制模拟}

内存管理是操作系统的另一核心功能，其目标是有效利用有限的物理内存资源，同时为每个进程提供独立的地址空间。平台实现了从简单的分区管理到复杂的虚拟内存管理的完整演进过程。

在连续内存分配方案中，首次适应（First Fit）算法从内存低地址开始查找第一个足够大的空闲块，平均查找时间较短但容易在低地址区产生大量小碎片。最佳适应（Best Fit）算法选择大小最接近请求的空闲块，虽然空间利用率较高，但会产生大量难以利用的微小碎片。最坏适应（Worst Fit）算法选择最大的空闲块，期望剩余部分仍然足够大，但实践效果往往不佳。

分页机制将物理内存划分为固定大小的页框（Frame），逻辑地址空间划分为同样大小的页（Page）。对于32位系统，若页大小为4KB，逻辑地址可分解为：
\begin{equation}
\text{逻辑地址} = \text{页号}(20\text{位}) + \text{页内偏移}(12\text{位})
\end{equation}
地址转换通过页表（Page Table）完成。设页表项大小为4B，则页表本身需要$2^{20} \times 4B = 4MB$的连续内存，这导致了多级页表的产生。平台展示了二级页表的地址转换过程，逻辑地址被分解为：外层页号（10位）+ 内层页号（10位）+ 页内偏移（12位）。

快表（TLB, Translation Lookaside Buffer）是一个高速缓存，存储最近使用的页表项。设TLB命中率为$\alpha$，TLB访问时间为$t_T$，内存访问时间为$t_M$，则有效内存访问时间为：
\begin{equation}
EAT = \alpha \times (t_T + t_M) + (1-\alpha) \times (t_T + 2t_M)
\end{equation}
其中第二项的$2t_M$表示一次页表访问和一次实际内存访问。典型情况下，$\alpha$可达0.98以上，TLB显著提升了地址转换效率。

页面置换算法在物理内存不足时决定淘汰哪个页面。FIFO（First In First Out）算法淘汰最早调入的页面，实现简单但存在Belady异常（增加页框数反而增加缺页率）。LRU（Least Recently Used）算法淘汰最近最久未使用的页面，性能较好但实现代价高，通常通过时间戳或栈来近似实现。OPT（Optimal）算法淘汰未来最长时间不被访问的页面，这是理论最优算法但无法实际实现（需要预知未来），常作为性能上界的参考。平台通过模拟页面访问序列，动态展示各算法的缺页中断过程和性能差异。

\subsection{死锁检测与避免}

死锁是多个进程因竞争资源而陷入永久等待的状态。死锁产生需要同时满足四个必要条件：互斥、占有并等待、非抢占、循环等待。银行家算法是最著名的死锁避免算法，由Dijkstra提出。

设系统有$n$个进程和$m$类资源，定义以下数据结构：
\begin{itemize}
    \item Available向量：$Available[j] = k$表示资源类型$j$有$k$个实例可用
    \item Max矩阵：$Max[i,j] = k$表示进程$i$最多需要$k$个资源$j$的实例
    \item Allocation矩阵：$Allocation[i,j] = k$表示进程$i$当前持有$k$个资源$j$的实例
    \item Need矩阵：$Need[i,j] = Max[i,j] - Allocation[i,j]$表示进程$i$还需要多少资源$j$
\end{itemize}

安全性检测算法通过寻找一个进程执行序列$<P_1, P_2, ..., P_n>$，使得对每个$P_i$，其资源需求可以被当前可用资源和所有$P_j$（$j<i$）释放的资源满足。该算法的时间复杂度为$O(m \times n^2)$。

平台允许用户输入资源分配矩阵和请求向量，系统自动判断当前状态是否安全，并可视化展示安全序列的查找过程或死锁的形成过程，帮助学习者深入理解死锁的本质和预防机制。

\section{计算机网络模块}

计算机网络模块旨在揭示网络通信的内在机制，通过分层协议栈的可视化和核心算法的动态演示，帮助学习者构建对网络系统的整体性理解。

\subsection{协议栈封装与解封装}

现代网络系统采用分层架构，最典型的模型是TCP/IP五层模型：应用层、传输层、网络层、数据链路层和物理层。每一层为上层提供服务，同时使用下层提供的服务，这种抽象和封装的思想是软件工程的核心原则之一。

数据在发送端自上而下传递时，每一层都会添加该层的协议头部（Header），这个过程称为封装（Encapsulation）。以一个HTTP请求为例，应用层数据首先被传递到传输层，TCP协议添加TCP头部（包含源端口、目的端口、序列号、确认号、窗口大小等信息，通常为20字节），形成TCP段（Segment）。TCP段传递到网络层后，IP协议添加IP头部（包含源IP地址、目的IP地址、TTL、协议类型等，IPv4头部最少20字节），形成IP数据报（Datagram）。IP数据报在数据链路层被封装为帧（Frame），添加以太网头部（包含源MAC地址、目的MAC地址、类型字段，共14字节）和尾部（4字节CRC校验），最后在物理层转换为比特流通过物理介质传输。

接收端进行相反的解封装（Decapsulation）过程。设应用层数据大小为$D$字节，则经过各层封装后的总大小可以表示为：
\begin{equation}
Size_{total} = D + H_{TCP} + H_{IP} + H_{Ethernet} + T_{Ethernet}
\end{equation}
对于典型的HTTP请求，若应用层数据为1000字节，则总大小约为$1000 + 20 + 20 + 14 + 4 = 1058$字节。协议开销（Protocol Overhead）为$58/1058 \approx 5.5\%$。当数据量较小时，协议开销占比显著增加，这解释了为何应用层协议要避免过多的小包传输。

平台通过动画清晰展示数据在各层间的垂直传递过程，以及头部信息的逐层添加和剥离，帮助学习者理解分层架构的工作原理和各层协议的作用。

\subsection{路由算法与最短路径计算}

路由算法是网络层的核心功能，负责为数据包选择从源到目的地的最优路径。距离向量（Distance Vector）算法和链路状态（Link State）算法是两种基本的路由算法范式。

距离向量算法基于Bellman-Ford算法，每个路由器维护一个到所有目的网络的距离向量，并定期与相邻路由器交换该向量。设$D_x(y)$表示从节点$x$到节点$y$的最短距离估计值，$c(x,v)$表示从$x$到直接相邻节点$v$的链路代价，则Bellman-Ford方程为：
\begin{equation}
D_x(y) = \min_v \{c(x,v) + D_v(y)\}
\end{equation}
该算法的优点是实现简单，缺点是收敛速度慢，且存在"无穷计数"（Count-to-Infinity）问题。

链路状态算法基于Dijkstra算法，每个路由器首先通过洪泛（Flooding）获得全网拓扑信息，然后在本地运行Dijkstra算法计算到所有目的地的最短路径。算法的时间复杂度为$O(n^2)$（使用数组实现）或$O(n\log n + m)$（使用堆实现），其中$n$为节点数，$m$为边数。

\subsection{TCP拥塞控制机制}

TCP拥塞控制是保证网络稳定运行的关键机制。TCP维护一个拥塞窗口（cwnd），慢启动阶段cwnd呈指数增长，每个RTT后翻倍，即$cwnd(t+RTT) = 2 \times cwnd(t)$。当cwnd达到慢启动阈值后，进入拥塞避免阶段，采用加性增（Additive Increase）策略：
\begin{equation}
cwnd_{new} = cwnd_{old} + \frac{1}{cwnd_{old}}
\end{equation}
当检测到丢包时，采取乘性减（Multiplicative Decrease）策略。这种AIMD策略能够使多个TCP流公平地共享网络带宽。

\section{用户系统模块}
\subsection{用户认证}
使用 Firebase Authentication，支持邮箱/密码、主流第三方平台（如GitHub）登录。

\subsection{用户数据管理}
\begin{itemize}
    \item \textbf{学习进度:} 记录用户在每个知识点上的学习状态（已学习、待复习）。
    \item \textbf{实验数据:} 保存用户自定义的输入数据和实验场景，便于回顾。
\end{itemize}
