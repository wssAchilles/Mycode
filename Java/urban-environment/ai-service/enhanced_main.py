#!/usr/bin/env python3
# -*- coding: utf-8 -*-

"""
å¢žå¼ºç‰ˆAIå¼‚å¸¸æ£€æµ‹é¢„æµ‹æœåŠ¡ - enhanced_main.py
åŠŸèƒ½ï¼š
1. æ”¯æŒå¤šç‰¹å¾å¼‚å¸¸æ£€æµ‹
2. é›†æˆå¤šç§ç®—æ³•çš„é¢„æµ‹ç»“æžœ
3. æ™ºèƒ½é˜ˆå€¼è°ƒæ•´
4. å®žæ—¶é¢„è­¦ç³»ç»Ÿ
5. è¯¦ç»†çš„é¢„æµ‹åˆ†æžæŠ¥å‘Š
"""

import os
import joblib
import numpy as np
import pandas as pd
from fastapi import FastAPI, HTTPException, BackgroundTasks
from pydantic import BaseModel, Field
import logging
from typing import Dict, Any, List, Optional
import uvicorn
from contextlib import asynccontextmanager
from datetime import datetime, timezone
import asyncio

# é…ç½®æ—¥å¿—
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(levelname)s - %(message)s'
)
logger = logging.getLogger(__name__)

# å…¨å±€å˜é‡
enhanced_model = None
feature_scaler = None
model_metadata = None
all_models = None


class SensorReading(BaseModel):
    """ä¼ æ„Ÿå™¨è¯»æ•°è¯·æ±‚æ¨¡åž‹"""
    pm25: float = Field(..., ge=0.0, le=500.0, description="PM2.5æ•°å€¼ï¼ŒèŒƒå›´0-500")
    temperature: Optional[float] = Field(None, ge=-50.0, le=70.0, description="æ¸©åº¦ï¼ŒèŒƒå›´-50åˆ°70Â°C")
    humidity: Optional[float] = Field(None, ge=0.0, le=100.0, description="æ¹¿åº¦ï¼ŒèŒƒå›´0-100%")
    latitude: Optional[float] = Field(None, ge=-90.0, le=90.0, description="çº¬åº¦")
    longitude: Optional[float] = Field(None, ge=-180.0, le=180.0, description="ç»åº¦")
    device_id: str = Field(..., description="è®¾å¤‡ID")
    timestamp: Optional[str] = Field(None, description="æ—¶é—´æˆ³ (ISOæ ¼å¼)")
    
    class Config:
        json_schema_extra = {
            "example": {
                "pm25": 25.6,
                "temperature": 23.5,
                "humidity": 65.2,
                "latitude": 35.6895,
                "longitude": 139.6917,
                "device_id": "sensor-tokyo-01",
                "timestamp": "2025-09-17T10:00:00Z"
            }
        }


class EnhancedPredictionResponse(BaseModel):
    """å¢žå¼ºé¢„æµ‹ç»“æžœå“åº”æ¨¡åž‹"""
    is_anomaly: bool = Field(..., description="æ˜¯å¦ä¸ºå¼‚å¸¸å€¼")
    anomaly_score: float = Field(..., description="å¼‚å¸¸åˆ†æ•°ï¼Œè¶Šè´Ÿè¶Šå¼‚å¸¸")
    confidence: float = Field(..., description="ç½®ä¿¡åº¦ï¼Œ0-1ä¹‹é—´")
    risk_level: str = Field(..., description="é£Žé™©ç­‰çº§: low/medium/high/critical")
    
    # è¾“å…¥æ•°æ®
    pm25_value: float = Field(..., description="è¾“å…¥çš„PM2.5å€¼")
    device_id: str = Field(..., description="è®¾å¤‡ID")
    
    # å¢žå¼ºåˆ†æž
    feature_analysis: Dict[str, float] = Field(..., description="ç‰¹å¾åˆ†æž")
    model_ensemble: Dict[str, Any] = Field(..., description="å¤šæ¨¡åž‹é›†æˆç»“æžœ")
    threshold_analysis: Dict[str, float] = Field(..., description="é˜ˆå€¼åˆ†æž")
    
    # å»ºè®®
    recommendations: List[str] = Field(..., description="å»ºè®®æŽªæ–½")
    alert_level: int = Field(..., ge=0, le=4, description="è­¦æŠ¥çº§åˆ« 0-4")
    
    class Config:
        json_schema_extra = {
            "example": {
                "is_anomaly": True,
                "anomaly_score": -0.15,
                "confidence": 0.85,
                "risk_level": "high",
                "pm25_value": 35.6,
                "device_id": "sensor-tokyo-01",
                "feature_analysis": {
                    "pm25_normalized": 1.2,
                    "time_factor": 0.8,
                    "location_factor": 0.9
                },
                "model_ensemble": {
                    "isolation_forest": -0.15,
                    "one_class_svm": -0.12,
                    "elliptic_envelope": -0.18,
                    "consensus": "anomaly"
                },
                "threshold_analysis": {
                    "p95_threshold": -0.0078,
                    "p97_threshold": -0.0301,
                    "current_score": -0.15
                },
                "recommendations": [
                    "ç«‹å³æ£€æŸ¥ä¼ æ„Ÿå™¨å‘¨å›´çŽ¯å¢ƒ",
                    "è€ƒè™‘å¯åŠ¨åº”æ€¥å“åº”ç¨‹åº",
                    "é€šçŸ¥ç›¸å…³äººå‘˜"
                ],
                "alert_level": 3
            }
        }


class AlertManager:
    """è­¦æŠ¥ç®¡ç†å™¨"""
    
    def __init__(self):
        self.alert_history = []
        self.active_alerts = {}
        
    def should_trigger_alert(self, device_id: str, anomaly_score: float, confidence: float) -> bool:
        """åˆ¤æ–­æ˜¯å¦åº”è¯¥è§¦å‘è­¦æŠ¥"""
        # é«˜ç½®ä¿¡åº¦çš„å¼‚å¸¸å€¼è§¦å‘è­¦æŠ¥
        return confidence > 0.7 and anomaly_score < -0.05
        
    def get_alert_level(self, anomaly_score: float, confidence: float) -> int:
        """èŽ·å–è­¦æŠ¥çº§åˆ« 0-4"""
        if anomaly_score > 0:
            return 0  # æ­£å¸¸
        elif anomaly_score > -0.05:
            return 1  # è½»å¾®å¼‚å¸¸
        elif anomaly_score > -0.1:
            return 2  # ä¸­åº¦å¼‚å¸¸
        elif anomaly_score > -0.2:
            return 3  # é«˜åº¦å¼‚å¸¸
        else:
            return 4  # ä¸¥é‡å¼‚å¸¸
    
    def generate_recommendations(self, pm25: float, anomaly_score: float, alert_level: int) -> List[str]:
        """ç”Ÿæˆå»ºè®®æŽªæ–½"""
        recommendations = []
        
        if alert_level == 0:
            recommendations.append("çŽ¯å¢ƒæ•°æ®æ­£å¸¸ï¼Œç»§ç»­ç›‘æŽ§")
        elif alert_level == 1:
            recommendations.append("è½»å¾®å¼‚å¸¸ï¼Œå»ºè®®æŒç»­è§‚å¯Ÿ")
            recommendations.append("æ£€æŸ¥ä¼ æ„Ÿå™¨æ ¡å‡†çŠ¶æ€")
        elif alert_level == 2:
            recommendations.append("ä¸­åº¦å¼‚å¸¸ï¼Œå»ºè®®æ£€æŸ¥çŽ¯å¢ƒå› ç´ ")
            recommendations.append("è€ƒè™‘å¢žåŠ ç›‘æµ‹é¢‘çŽ‡")
        elif alert_level == 3:
            recommendations.append("é«˜åº¦å¼‚å¸¸ï¼Œç«‹å³æ£€æŸ¥ä¼ æ„Ÿå™¨å’Œå‘¨å›´çŽ¯å¢ƒ")
            recommendations.append("é€šçŸ¥çŽ¯å¢ƒç›‘æµ‹äººå‘˜")
            recommendations.append("è€ƒè™‘å¯åŠ¨åº”æ€¥å“åº”")
        else:  # alert_level == 4
            recommendations.append("ä¸¥é‡å¼‚å¸¸ï¼ç«‹å³é‡‡å–è¡ŒåŠ¨")
            recommendations.append("å¯åŠ¨åº”æ€¥å“åº”ç¨‹åº")
            recommendations.append("é€šçŸ¥æ‰€æœ‰ç›¸å…³è´£ä»»äºº")
            recommendations.append("è€ƒè™‘ç–æ•£æˆ–é˜²æŠ¤æŽªæ–½")
        
        # PM2.5ç‰¹å®šå»ºè®®
        if pm25 > 75:
            recommendations.append("PM2.5æµ“åº¦è¿‡é«˜ï¼Œå»ºè®®å‡å°‘æˆ·å¤–æ´»åŠ¨")
        elif pm25 > 35:
            recommendations.append("PM2.5æµ“åº¦åé«˜ï¼Œæ•æ„Ÿäººç¾¤åº”æ³¨æ„é˜²æŠ¤")
            
        return recommendations


# å…¨å±€è­¦æŠ¥ç®¡ç†å™¨
alert_manager = AlertManager()


def load_enhanced_models():
    """åŠ è½½å¢žå¼ºæ¨¡åž‹å’Œç›¸å…³ç»„ä»¶"""
    global enhanced_model, feature_scaler, model_metadata, all_models
    
    script_dir = os.path.dirname(os.path.abspath(__file__))
    model_dir = os.path.join(script_dir, "models")
    
    try:
        # åŠ è½½ä¸»æ¨¡åž‹
        enhanced_model_path = os.path.join(model_dir, 'enhanced_anomaly_model.joblib')
        if os.path.exists(enhanced_model_path):
            enhanced_model = joblib.load(enhanced_model_path)
            logger.info("âœ… å¢žå¼ºä¸»æ¨¡åž‹åŠ è½½æˆåŠŸ")
        else:
            # å›žé€€åˆ°åŽŸå§‹æ¨¡åž‹
            original_model_path = os.path.join(model_dir, 'anomaly_model.joblib')
            if os.path.exists(original_model_path):
                enhanced_model = joblib.load(original_model_path)
                logger.info("âš ï¸ ä½¿ç”¨åŽŸå§‹æ¨¡åž‹ä½œä¸ºå›žé€€")
            else:
                raise FileNotFoundError("æ‰¾ä¸åˆ°ä»»ä½•å¯ç”¨çš„æ¨¡åž‹æ–‡ä»¶")
        
        # åŠ è½½ç‰¹å¾ç¼©æ”¾å™¨
        scaler_path = os.path.join(model_dir, 'feature_scaler.joblib')
        if os.path.exists(scaler_path):
            feature_scaler = joblib.load(scaler_path)
            logger.info("âœ… ç‰¹å¾ç¼©æ”¾å™¨åŠ è½½æˆåŠŸ")
        
        # åŠ è½½æ¨¡åž‹å…ƒæ•°æ®
        metadata_path = os.path.join(model_dir, 'model_metadata.joblib')
        if os.path.exists(metadata_path):
            model_metadata = joblib.load(metadata_path)
            logger.info("âœ… æ¨¡åž‹å…ƒæ•°æ®åŠ è½½æˆåŠŸ")
            logger.info(f"ç‰¹å¾æ•°é‡: {len(model_metadata.get('feature_columns', []))}")
        
        # åŠ è½½æ‰€æœ‰æ¨¡åž‹ï¼ˆç”¨äºŽé›†æˆé¢„æµ‹ï¼‰
        all_models_path = os.path.join(model_dir, 'all_models.joblib')
        if os.path.exists(all_models_path):
            all_models = joblib.load(all_models_path)
            logger.info(f"âœ… é›†æˆæ¨¡åž‹åŠ è½½æˆåŠŸ ({len(all_models)} ä¸ªæ¨¡åž‹)")
        
        return True
        
    except Exception as e:
        logger.error(f"æ¨¡åž‹åŠ è½½å¤±è´¥: {e}")
        return False


def engineer_single_features(reading: SensorReading) -> np.ndarray:
    """ä¸ºå•ä¸ªè¯»æ•°ç”Ÿæˆç‰¹å¾"""
    try:
        # è§£æžæ—¶é—´æˆ³
        if reading.timestamp:
            timestamp = datetime.fromisoformat(reading.timestamp.replace('Z', '+00:00'))
        else:
            timestamp = datetime.now(timezone.utc)
        
        # åŸºç¡€ç‰¹å¾
        features = {
            'pm25': reading.pm25,
            'latitude': reading.latitude or 35.6895,  # é»˜è®¤å€¼
            'longitude': reading.longitude or 139.6917,
        }
        
        # æ—¶é—´ç‰¹å¾
        hour = timestamp.hour
        day_of_week = timestamp.weekday()
        
        features.update({
            'hour_sin': np.sin(2 * np.pi * hour / 24),
            'hour_cos': np.cos(2 * np.pi * hour / 24),
            'day_sin': np.sin(2 * np.pi * day_of_week / 7),
            'day_cos': np.cos(2 * np.pi * day_of_week / 7),
        })
        
        # ç”±äºŽæ˜¯å•ä¸ªè¯»æ•°ï¼Œæ— æ³•è®¡ç®—æ—¶é—´åºåˆ—ç‰¹å¾ï¼Œä½¿ç”¨é»˜è®¤å€¼
        default_features = {
            'pm25_mean': reading.pm25,
            'pm25_std': 0.0,
            'pm25_min': reading.pm25,
            'pm25_max': reading.pm25,
            'pm25_diff': 0.0,
            'pm25_pct_change': 0.0,
            'pm25_lag1': reading.pm25,
            'pm25_lag2': reading.pm25,
            'location_change': 0.0,
        }
        
        features.update(default_features)
        
        # å¦‚æžœæœ‰æ¨¡åž‹å…ƒæ•°æ®ï¼Œä½¿ç”¨æŒ‡å®šçš„ç‰¹å¾é¡ºåº
        if model_metadata and 'feature_columns' in model_metadata:
            feature_columns = model_metadata['feature_columns']
            feature_array = np.array([features.get(col, 0.0) for col in feature_columns])
        else:
            # ä½¿ç”¨é»˜è®¤ç‰¹å¾é¡ºåº
            default_columns = [
                'pm25', 'pm25_mean', 'pm25_std', 'pm25_min', 'pm25_max',
                'pm25_diff', 'pm25_pct_change', 'pm25_lag1', 'pm25_lag2',
                'latitude', 'longitude', 'location_change',
                'hour_sin', 'hour_cos', 'day_sin', 'day_cos'
            ]
            feature_array = np.array([features.get(col, 0.0) for col in default_columns])
        
        return feature_array.reshape(1, -1)
        
    except Exception as e:
        logger.error(f"ç‰¹å¾å·¥ç¨‹å¤±è´¥: {e}")
        # è¿”å›žæœ€ç®€å•çš„ç‰¹å¾ï¼šåªæœ‰PM2.5
        return np.array([[reading.pm25]])


def get_risk_level(anomaly_score: float, confidence: float) -> str:
    """èŽ·å–é£Žé™©ç­‰çº§"""
    if anomaly_score > 0:
        return "low"
    elif anomaly_score > -0.05 or confidence < 0.5:
        return "low"
    elif anomaly_score > -0.1 or confidence < 0.7:
        return "medium"
    elif anomaly_score > -0.2 or confidence < 0.85:
        return "high"
    else:
        return "critical"


@asynccontextmanager
async def lifespan(app: FastAPI):
    """åº”ç”¨ç”Ÿå‘½å‘¨æœŸç®¡ç†"""
    logger.info("ðŸš€ å¢žå¼ºç‰ˆAIå¼‚å¸¸æ£€æµ‹æœåŠ¡å¯åŠ¨ä¸­...")
    
    success = load_enhanced_models()
    if not success:
        logger.error("âŒ æ¨¡åž‹åŠ è½½å¤±è´¥ï¼ŒæœåŠ¡æ— æ³•å¯åŠ¨")
        raise Exception("Model loading failed")
    
    logger.info("âœ… å¢žå¼ºç‰ˆAIæœåŠ¡å·²å°±ç»ª")
    logger.info("ðŸŽ¯ æ”¯æŒå¤šç‰¹å¾åˆ†æžã€é›†æˆé¢„æµ‹ã€æ™ºèƒ½é¢„è­¦")
    
    yield
    
    logger.info("ðŸ”„ å¢žå¼ºç‰ˆAIæœåŠ¡æ­£åœ¨å…³é—­...")


# åˆ›å»ºFastAPIåº”ç”¨
app = FastAPI(
    title="å¢žå¼ºç‰ˆAIå¼‚å¸¸æ£€æµ‹æœåŠ¡",
    description="åŸºäºŽå¤šç®—æ³•é›†æˆçš„çŽ¯å¢ƒæ•°æ®å¼‚å¸¸æ£€æµ‹å¾®æœåŠ¡ï¼Œæ”¯æŒç‰¹å¾å·¥ç¨‹ã€æ™ºèƒ½é˜ˆå€¼ã€å®žæ—¶é¢„è­¦",
    version="2.0.0",
    lifespan=lifespan
)


@app.get("/")
async def root():
    """æ ¹è·¯å¾„ - æœåŠ¡çŠ¶æ€æ£€æŸ¥"""
    return {
        "service": "å¢žå¼ºç‰ˆAIå¼‚å¸¸æ£€æµ‹æœåŠ¡",
        "status": "è¿è¡Œä¸­",
        "version": "2.0.0",
        "features": [
            "å¤šç‰¹å¾å¼‚å¸¸æ£€æµ‹",
            "ç®—æ³•é›†æˆé¢„æµ‹",
            "æ™ºèƒ½é˜ˆå€¼è°ƒæ•´",
            "å®žæ—¶é¢„è­¦ç³»ç»Ÿ",
            "è¯¦ç»†åˆ†æžæŠ¥å‘Š"
        ],
        "model_loaded": enhanced_model is not None,
        "scaler_loaded": feature_scaler is not None,
        "metadata_loaded": model_metadata is not None,
        "ensemble_models": len(all_models) if all_models else 0,
        "endpoints": {
            "health": "/health",
            "predict": "/predict",
            "enhanced_predict": "/enhanced-predict",
            "model_info": "/model-info",
            "alerts": "/alerts",
            "docs": "/docs"
        }
    }


@app.get("/health")
async def health_check():
    """å¥åº·æ£€æŸ¥ç«¯ç‚¹"""
    model_status = "å·²åŠ è½½" if enhanced_model is not None else "æœªåŠ è½½"
    
    return {
        "status": "healthy",
        "model_status": model_status,
        "scaler_status": "å·²åŠ è½½" if feature_scaler else "æœªåŠ è½½",
        "metadata_status": "å·²åŠ è½½" if model_metadata else "æœªåŠ è½½",
        "service": "å¢žå¼ºç‰ˆAIå¼‚å¸¸æ£€æµ‹æœåŠ¡",
        "version": "2.0.0",
        "timestamp": datetime.now().isoformat()
    }


@app.post("/enhanced-predict", response_model=EnhancedPredictionResponse)
async def enhanced_predict_anomaly(reading: SensorReading):
    """
    å¢žå¼ºå¼‚å¸¸æ£€æµ‹é¢„æµ‹ç«¯ç‚¹
    
    Args:
        reading: ä¼ æ„Ÿå™¨è¯»æ•°
    
    Returns:
        EnhancedPredictionResponse: è¯¦ç»†é¢„æµ‹ç»“æžœ
    """
    global enhanced_model, feature_scaler, model_metadata, all_models
    
    try:
        # æ£€æŸ¥æ¨¡åž‹æ˜¯å¦å·²åŠ è½½
        if enhanced_model is None:
            raise HTTPException(
                status_code=500,
                detail="AIæ¨¡åž‹æœªåŠ è½½ï¼Œè¯·æ£€æŸ¥æœåŠ¡çŠ¶æ€"
            )
        
        # ç‰¹å¾å·¥ç¨‹
        features = engineer_single_features(reading)
        
        # ç‰¹å¾ç¼©æ”¾
        if feature_scaler is not None:
            features_scaled = feature_scaler.transform(features)
        else:
            features_scaled = features
        
        # ä¸»æ¨¡åž‹é¢„æµ‹
        prediction = enhanced_model.predict(features_scaled)[0]
        anomaly_score = enhanced_model.decision_function(features_scaled)[0]
        
        # åŸºæœ¬å¼‚å¸¸åˆ¤æ–­
        is_anomaly = prediction == -1
        
        # è®¡ç®—ç½®ä¿¡åº¦
        confidence = min(abs(anomaly_score) * 2, 1.0)
        
        # é›†æˆæ¨¡åž‹é¢„æµ‹
        model_ensemble = {}
        if all_models:
            for model_name, model in all_models.items():
                try:
                    pred = model.predict(features_scaled)[0]
                    if hasattr(model, 'decision_function'):
                        score = model.decision_function(features_scaled)[0]
                    else:
                        score = pred
                    model_ensemble[model_name] = {
                        "prediction": "anomaly" if pred == -1 else "normal",
                        "score": float(score)
                    }
                except Exception as e:
                    logger.warning(f"æ¨¡åž‹ {model_name} é¢„æµ‹å¤±è´¥: {e}")
        
        # é£Žé™©ç­‰çº§è¯„ä¼°
        risk_level = get_risk_level(anomaly_score, confidence)
        
        # è­¦æŠ¥çº§åˆ«
        alert_level = alert_manager.get_alert_level(anomaly_score, confidence)
        
        # ç‰¹å¾åˆ†æž
        feature_analysis = {
            "pm25_normalized": float(reading.pm25 / 50.0),  # å½’ä¸€åŒ–åˆ°æ ‡å‡†å€¼
            "time_factor": abs(np.sin(2 * np.pi * datetime.now().hour / 24)),
            "confidence_score": float(confidence)
        }
        
        # é˜ˆå€¼åˆ†æž
        threshold_analysis = {}
        if model_metadata and 'thresholds' in model_metadata:
            thresholds = model_metadata['thresholds']
            for name, info in thresholds.items():
                threshold_analysis[f"{name}_threshold"] = float(info['threshold'])
        
        threshold_analysis["current_score"] = float(anomaly_score)
        
        # ç”Ÿæˆå»ºè®®
        recommendations = alert_manager.generate_recommendations(
            reading.pm25, anomaly_score, alert_level
        )
        
        # æž„å»ºå“åº”
        result = EnhancedPredictionResponse(
            is_anomaly=is_anomaly,
            anomaly_score=round(anomaly_score, 4),
            confidence=round(confidence, 4),
            risk_level=risk_level,
            pm25_value=reading.pm25,
            device_id=reading.device_id,
            feature_analysis=feature_analysis,
            model_ensemble=model_ensemble or {"main_model": {"prediction": "anomaly" if is_anomaly else "normal", "score": float(anomaly_score)}},
            threshold_analysis=threshold_analysis,
            recommendations=recommendations,
            alert_level=alert_level
        )
        
        # è®°å½•é¢„æµ‹æ—¥å¿—
        status = "å¼‚å¸¸" if is_anomaly else "æ­£å¸¸"
        logger.info(
            f"å¢žå¼ºé¢„æµ‹å®Œæˆ: è®¾å¤‡={reading.device_id}, PM2.5={reading.pm25}, "
            f"ç»“æžœ={status}, åˆ†æ•°={anomaly_score:.4f}, ç½®ä¿¡åº¦={confidence:.4f}, "
            f"é£Žé™©ç­‰çº§={risk_level}, è­¦æŠ¥çº§åˆ«={alert_level}"
        )
        
        # æ£€æŸ¥æ˜¯å¦éœ€è¦è§¦å‘è­¦æŠ¥
        if alert_manager.should_trigger_alert(reading.device_id, anomaly_score, confidence):
            logger.warning(f"âš ï¸ å¼‚å¸¸è­¦æŠ¥: è®¾å¤‡ {reading.device_id} æ£€æµ‹åˆ°ä¸¥é‡å¼‚å¸¸")
        
        return result
        
    except HTTPException:
        raise
    except Exception as e:
        logger.error(f"å¢žå¼ºé¢„æµ‹å¤±è´¥: {e}")
        raise HTTPException(
            status_code=500,
            detail=f"å¢žå¼ºé¢„æµ‹å¤±è´¥: {str(e)}"
        )


# ä¿æŒå‘åŽå…¼å®¹çš„ç®€å•é¢„æµ‹ç«¯ç‚¹
@app.post("/predict")
async def simple_predict_anomaly(reading: Dict[str, float]):
    """
    ç®€å•å¼‚å¸¸æ£€æµ‹é¢„æµ‹ç«¯ç‚¹ï¼ˆå‘åŽå…¼å®¹ï¼‰
    """
    try:
        # è½¬æ¢ä¸ºå¢žå¼ºè¾“å…¥æ ¼å¼
        enhanced_reading = SensorReading(
            pm25=reading.get("pm25", 0),
            device_id=reading.get("device_id", "unknown"),
            temperature=reading.get("temperature"),
            humidity=reading.get("humidity"),
            latitude=reading.get("latitude"),
            longitude=reading.get("longitude")
        )
        
        # è°ƒç”¨å¢žå¼ºé¢„æµ‹
        enhanced_result = await enhanced_predict_anomaly(enhanced_reading)
        
        # è¿”å›žç®€åŒ–ç»“æžœ
        return {
            "is_anomaly": enhanced_result.is_anomaly,
            "anomaly_score": enhanced_result.anomaly_score,
            "confidence": enhanced_result.confidence,
            "pm25_value": enhanced_result.pm25_value
        }
        
    except Exception as e:
        logger.error(f"ç®€å•é¢„æµ‹å¤±è´¥: {e}")
        raise HTTPException(
            status_code=500,
            detail=f"é¢„æµ‹å¤±è´¥: {str(e)}"
        )


@app.get("/model-info")
async def get_enhanced_model_info():
    """èŽ·å–å¢žå¼ºæ¨¡åž‹ä¿¡æ¯"""
    if enhanced_model is None:
        raise HTTPException(status_code=503, detail="æ¨¡åž‹æœªåŠ è½½")
    
    info = {
        "model_type": "Enhanced Environmental Anomaly Detector",
        "version": "2.0.0",
        "primary_algorithm": "IsolationForest",
        "model_loaded": True,
        "features": {
            "feature_engineering": True,
            "multi_algorithm_ensemble": True,
            "intelligent_thresholding": True,
            "real_time_alerting": True
        }
    }
    
    if model_metadata:
        info.update({
            "feature_count": len(model_metadata.get('feature_columns', [])),
            "feature_columns": model_metadata.get('feature_columns', []),
            "training_time": model_metadata.get('training_time', 'unknown'),
            "thresholds": model_metadata.get('thresholds', {})
        })
    
    if all_models:
        info["ensemble_models"] = list(all_models.keys())
    
    return info


@app.get("/alerts")
async def get_alerts():
    """èŽ·å–è­¦æŠ¥çŠ¶æ€"""
    return {
        "alert_history_count": len(alert_manager.alert_history),
        "active_alerts_count": len(alert_manager.active_alerts),
        "alert_levels": {
            "0": "æ­£å¸¸",
            "1": "è½»å¾®å¼‚å¸¸",
            "2": "ä¸­åº¦å¼‚å¸¸", 
            "3": "é«˜åº¦å¼‚å¸¸",
            "4": "ä¸¥é‡å¼‚å¸¸"
        }
    }


if __name__ == "__main__":
    # æœ¬åœ°å¼€å‘è¿è¡Œ
    uvicorn.run(
        "enhanced_main:app",
        host="0.0.0.0",
        port=8000,
        reload=False,
        log_level="info"
    )