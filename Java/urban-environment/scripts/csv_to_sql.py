#!/usr/bin/env python
# -*- coding: utf-8 -*-

import csv
import os

def csv_to_sql_inserts(csv_file_path, output_file_path, table_name, batch_size=500):
    """
    å°†CSVæ–‡ä»¶è½¬æ¢ä¸ºSQL INSERTè¯­å¥
    
    Args:
        csv_file_path (str): CSVæ–‡ä»¶è·¯å¾„
        output_file_path (str): è¾“å‡ºçš„SQLæ–‡ä»¶è·¯å¾„
        table_name (str): å®Œæ•´çš„è¡¨å
        batch_size (int): æ¯ä¸ªINSERTè¯­å¥åŒ…å«çš„è¡Œæ•°
    """
    
    if not os.path.exists(csv_file_path):
        print(f"é”™è¯¯: CSVæ–‡ä»¶ '{csv_file_path}' ä¸å­˜åœ¨")
        return
    
    try:
        with open(csv_file_path, 'r', encoding='utf-8') as csvfile:
            # ä½¿ç”¨CSVæ¨¡å—è¯»å–æ–‡ä»¶
            csv_reader = csv.DictReader(csvfile)
            
            # éªŒè¯åˆ—å
            expected_columns = ['id', 'device_id', 'latitude', 'longitude', 'pm25', 'timestamp']
            if not all(col in csv_reader.fieldnames for col in expected_columns):
                print(f"é”™è¯¯: CSVæ–‡ä»¶ç¼ºå°‘å¿…è¦çš„åˆ—ã€‚æœŸæœ›çš„åˆ—: {expected_columns}")
                print(f"å®é™…çš„åˆ—: {csv_reader.fieldnames}")
                return
            
            with open(output_file_path, 'w', encoding='utf-8') as output_file:
                rows = list(csv_reader)
                total_rows = len(rows)
                
                print(f"å¼€å§‹å¤„ç† {total_rows} è¡Œæ•°æ®...")
                
                # æŒ‰æ‰¹æ¬¡å¤„ç†æ•°æ®
                for i in range(0, total_rows, batch_size):
                    batch_rows = rows[i:i + batch_size]
                    
                    # å†™å…¥INSERTè¯­å¥çš„å¼€å¤´
                    output_file.write(f"INSERT INTO `{table_name}` (id, device_id, latitude, longitude, pm25, timestamp)\n")
                    output_file.write("VALUES\n")
                    
                    # å¤„ç†æ¯ä¸€è¡Œæ•°æ®
                    values_list = []
                    for row in batch_rows:
                        # æ ¼å¼åŒ–æ¯ä¸€è¡Œä¸ºSQL VALUESæ ¼å¼
                        values_line = f"    ({row['id']}, '{row['device_id']}', {row['latitude']}, {row['longitude']}, {row['pm25']}, '{row['timestamp']}')"
                        values_list.append(values_line)
                    
                    # è¿æ¥æ‰€æœ‰VALUESï¼Œæœ€åä¸€è¡Œç”¨åˆ†å·ç»“å°¾
                    output_file.write(",\n".join(values_list))
                    output_file.write(";\n\n")
                    
                    # æ˜¾ç¤ºè¿›åº¦
                    processed = min(i + batch_size, total_rows)
                    print(f"å·²å¤„ç† {processed}/{total_rows} è¡Œ ({processed/total_rows*100:.1f}%)")
                
                print(f"âœ… æˆåŠŸå®Œæˆï¼SQLè¯­å¥å·²ä¿å­˜åˆ°: {output_file_path}")
                print(f"ğŸ“Š æ€»å…± {total_rows} è¡Œæ•°æ®")
                print(f"ğŸ“¦ åˆ†æˆäº† {(total_rows + batch_size - 1) // batch_size} ä¸ªINSERTè¯­å¥")
                
    except UnicodeDecodeError:
        print("CSVæ–‡ä»¶ç¼–ç é”™è¯¯ï¼Œå°è¯•å…¶ä»–ç¼–ç ...")
        try:
            with open(csv_file_path, 'r', encoding='gbk') as csvfile:
                csv_reader = csv.DictReader(csvfile)
                # é‡å¤ä¸Šé¢çš„å¤„ç†é€»è¾‘...
                print("ä½¿ç”¨GBKç¼–ç æˆåŠŸè¯»å–æ–‡ä»¶")
        except Exception as e:
            print(f"ç¼–ç é”™è¯¯: {e}")
    except Exception as e:
        print(f"å¤„ç†è¿‡ç¨‹ä¸­å‘ç”Ÿé”™è¯¯: {e}")

def main():
    # é…ç½®å‚æ•°
    csv_file = "sensor_data_export_v2_clean.csv"
    output_file = "sensor_data_sql_inserts.txt"
    table_name = "urban-environment-471707.sensor_data.manual_sensor_data"
    batch_size = 500  # æ¯ä¸ªINSERTè¯­å¥åŒ…å«500è¡Œæ•°æ®
    
    print("=== CSVè½¬SQL INSERTè¯­å¥å·¥å…· ===")
    print(f"è¾“å…¥æ–‡ä»¶: {csv_file}")
    print(f"è¾“å‡ºæ–‡ä»¶: {output_file}")
    print(f"ç›®æ ‡è¡¨: {table_name}")
    print(f"æ‰¹æ¬¡å¤§å°: {batch_size} è¡Œ/æ‰¹æ¬¡")
    print("-" * 50)
    
    # æ‰§è¡Œè½¬æ¢
    csv_to_sql_inserts(csv_file, output_file, table_name, batch_size)

if __name__ == "__main__":
    main()